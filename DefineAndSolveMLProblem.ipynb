{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(bookReviewDataSet_filename, header=0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1973, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose the data Book Review dataset it has 1973 rows of reviews and two columns with one being the review itself and the other being whether or not it is a positive review or not. I will be predicting the sentiment in each review to see whether or not the review wrote positively about the book or not. This makes the label the Positive Review column. This is a supervised learning problem because we have labeled data and we are trying to solve a binary classification problem. My feature is the Review column containing all 1973 reviews. This is an important problem because it gives valuable insights on customer sentinment as gives feedback to publishers, retailers, and authors. This can help a company understand their audience and their preferences, and help find areas of improvement for the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>We will be using a Logistic Regression model initially since we are working with a binary classification problem in which Logistical Regression would be suitable. After this is all set, I hope to try out models like Random Forest, and RNNs. Other data preparation techniques I will need to apply would be probaly using TF-IDF vectorization to heklp me convert the text data into numerical features to work with also TF-IDF does all the normalizing for me.</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>I plan on evaluating and improving model performance using accuracy, precision, recall, f1 score, and ROC AUC score.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review             0\n",
      "Positive Review    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum()) # we have no null values ! yay !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    993\n",
       "True     980\n",
       "Name: Positive Review, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_count = df['Positive Review'].value_counts()\n",
    "review_count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 5000) # we can play around with the max_features and see which is better\n",
    "# too high max feature can cause overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data?Â \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't really have a new feature list as we are keeping the original review and using it for TF-IDF vectorization. \n",
    "\n",
    "I will just be using TF-IDF Vectorization for now, but I might try to figure out how to remove stop words and try lemmatization.\n",
    "\n",
    "My model initially will be Logistic Regression, but later on I intend on trying RNNs and Random Forest for improved performance.\n",
    "\n",
    "My plan to train my model is that:\n",
    "- I will first convert the raw text data into numerical features with TF-IDF\n",
    "- Split the data into training and testing\n",
    "- Train my Logisitc Regression model on TF-IDF transformed data\n",
    "- Evaluate the model using accuracy, precision, recall, F1 score, ROC AUC Score\n",
    "- Cross-validation\n",
    "- Try to improve model/optimize performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8556962025316456\n",
      "Precision: 0.8622448979591837\n",
      "Recall: 0.8492462311557789\n",
      "F1 Score: 0.8556962025316456\n",
      "ROC AUC: 0.91908522202851\n"
     ]
    }
   ],
   "source": [
    "y = df['Positive Review']\n",
    "X = df['Review']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "model = LogisticRegression(max_iter=200)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "y_pred_proba = model.predict_proba(X_test_tfidf)[:,1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 982, in _score\n",
      "    scores = scorer(estimator, X_test, y_test, **score_params)\n",
      "  File \"/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 253, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/metrics/_scorer.py\", line 344, in _score\n",
      "    response_method = _check_response_method(estimator, self._response_method)\n",
      "  File \"/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/utils/validation.py\", line 2106, in _check_response_method\n",
      "    raise AttributeError(\n",
      "AttributeError: TfidfVectorizer has none of the following attributes: predict.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best TF-IDF max_features:  {'max_features': 1000}\n"
     ]
    }
   ],
   "source": [
    "param_grid_tfidf = {\n",
    "    'max_features' : [1000, 3000, 5000, 7000, 10000]\n",
    "}\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'max_iter': [100, 200, 300]\n",
    "}\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "grid_search_tfidf = GridSearchCV(tfidf, param_grid_tfidf, cv=5, scoring='accuracy')\n",
    "grid_search_tfidf.fit(X_train, y_train)\n",
    "\n",
    "best_tfidf = grid_search_tfidf.best_estimator_\n",
    "\n",
    "X_train_tfidf = best_tfidf.transform(X_train)\n",
    "X_test_tfidf = best_tfidf.transform(X_test)\n",
    "\n",
    "print(\"Best TF-IDF max_features: \", grid_search_tfidf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best logistic regression parameters:  {'C': 100, 'max_iter': 100}\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "grid_search_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='accuracy')\n",
    "grid_search_lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "best_lr = grid_search_lr.best_estimator_\n",
    "\n",
    "y_pred = best_lr.predict(X_test_tfidf)\n",
    "y_pred_proba = best_lr.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "print(\"Best logistic regression parameters: \", grid_search_lr.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8151898734177215\n",
      "Precision: 0.815\n",
      "Recall: 0.8190954773869347\n",
      "F1 Score: 0.8170426065162907\n",
      "ROC AUC: 0.8942672546405497\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test,y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n",
    "print(f'ROC AUC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df: 1, Best LR Params: {'C': 100, 'max_iter': 100}, Accuracy: 0.8481012658227848\n",
      "min_df: 10, Best LR Params: {'C': 10, 'max_iter': 100}, Accuracy: 0.8531645569620253\n",
      "min_df: 100, Best LR Params: {'C': 10, 'max_iter': 100}, Accuracy: 0.7721518987341772\n",
      "min_df: 1000, Best LR Params: {'C': 1, 'max_iter': 100}, Accuracy: 0.5645569620253165\n",
      "Best Accuracy: 0.8531645569620253\n",
      "Best TF-IDF Parameters: {'min_df': 10}\n",
      "Best Logistic Regression Parameters: {'C': 10, 'max_iter': 100}\n",
      "\n",
      "Final Model Performance:\n",
      "Accuracy: 0.8531645569620253\n",
      "Precision: 0.8472906403940886\n",
      "Recall: 0.864321608040201\n",
      "F1 Score: 0.8557213930348259\n",
      "ROC AUC: 0.9138549892318736\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "best_params_tfidf = {}\n",
    "best_params_lr = {}\n",
    "\n",
    "param_grid_tfidf = {\n",
    "    'min_df': [1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "for min_df in param_grid_tfidf['min_df']:\n",
    "    \n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    lr = LogisticRegression()\n",
    "    grid_search_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='accuracy')\n",
    "    grid_search_lr.fit(X_train_tfidf, y_train)\n",
    "    \n",
    "    best_lr = grid_search_lr.best_estimator_\n",
    "    y_pred = best_lr.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"min_df: {min_df}, Best LR Params: {grid_search_lr.best_params_}, Accuracy: {accuracy}\")\n",
    "    \n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_params_tfidf = {'min_df': min_df}\n",
    "        best_params_lr = grid_search_lr.best_params_\n",
    "\n",
    "print(f\"Best Accuracy: {best_accuracy}\")\n",
    "print(f\"Best TF-IDF Parameters: {best_params_tfidf}\")\n",
    "print(f\"Best Logistic Regression Parameters: {best_params_lr}\")\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=best_params_tfidf['min_df'])\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "best_lr = LogisticRegression(C=best_params_lr['C'], max_iter=best_params_lr['max_iter'])\n",
    "best_lr.fit(X_train_tfidf, y_train)\n",
    "y_pred = best_lr.predict(X_test_tfidf)\n",
    "y_pred_proba = best_lr.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nFinal Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df: 1, Best RF Params: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 300}, Accuracy: 0.8379746835443038\n",
      "min_df: 10, Best RF Params: {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100}, Accuracy: 0.8202531645569621\n",
      "min_df: 100, Best RF Params: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 300}, Accuracy: 0.8075949367088607\n",
      "min_df: 1000, Best RF Params: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 100}, Accuracy: 0.5518987341772152\n",
      "Best Accuracy: 0.8379746835443038\n",
      "Best TF-IDF Params: {'min_df': 1}\n",
      "Best Random Forest Params: {'max_depth': 30, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "\n",
      "Final Model Performance:\n",
      "Accuracy: 0.8531645569620253\n",
      "Precision: 0.8472906403940886\n",
      "Recall: 0.864321608040201\n",
      "F1 Score: 0.8557213930348259\n",
      "ROC AUC: 0.919059583632448\n"
     ]
    }
   ],
   "source": [
    "param_grid_tfidf = {\n",
    "    'min_df': [1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10,20,30],\n",
    "    'min_samples_split': [2,5,10]\n",
    "}\n",
    "\n",
    "best_accuracy_rf = 0 \n",
    "best_params_tfidf_rf  = {}\n",
    "best_param_rf = {}\n",
    "\n",
    "for min_df in param_grid_tfidf['min_df']:\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=min_df)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    grid_search_rf = GridSearchCV(rf, param_grid_rf, cv=5, scoring='accuracy')\n",
    "    grid_search_rf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    best_rf = grid_search_rf.best_estimator_\n",
    "    y_pred_rf = best_rf.predict(X_test_tfidf)\n",
    "    accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "    print(f\"min_df: {min_df}, Best RF Params: {grid_search_rf.best_params_}, Accuracy: {accuracy_rf}\")\n",
    "\n",
    "    if accuracy_rf > best_accuracy_rf:\n",
    "        best_accuracy_rf = accuracy_rf\n",
    "        best_params_tfidf_rf = {'min_df': min_df}\n",
    "        best_params_rf = grid_search_rf.best_params_\n",
    "\n",
    "print(f\"Best Accuracy: {best_accuracy_rf}\")\n",
    "print(f\"Best TF-IDF Params: {best_params_tfidf_rf}\")\n",
    "print(f\"Best Random Forest Params: {best_params_rf}\")\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=best_params_tfidf_rf['min_df'])\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=best_params_rf['n_estimators'],\n",
    "    max_depth=best_params_rf['max_depth'],\n",
    "    min_samples_split=best_params_rf['min_samples_split']\n",
    ")\n",
    "best_rf.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = best_rf.predict(X_test_tfidf)\n",
    "y_pred_proba = best_rf.predict_proba(X_test_tfidf)[:, 1]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"\\nFinal Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"ROC AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon looking at the result, we can see that the initial model with TF-IDF Vectorizer with max_features set to 5000 and a Logistic Regression model with max_iter set to 200. The other models performed well too as they all hovered around a similar accuracy range. I think some steps I would take to further this and improve is to potentially test CNN or RNNs to improve performance since there's always room for improvement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
